[cfg_proto]
cfg_proto=proto/global.proto
cfg_proto_chunk=proto/global_chunk.proto

[exp]
cmd=
run_nn_script=run_nn
out_folder=exp/libri_LSTM_fmllr
seed=1234
use_cuda=True
multi_gpu=False
save_gpumem=False
N_epochs_tr=22
retrain=False

[dataset1]
data_name=train_clean_100
fea:fea_name=fmllr
    fea_lst=/usr/local/home/nesrez/kaldi/egs/librispeech/s5/fmllr/train_clean_100/feats.scp
    fea_opts=apply-cmvn --utt2spk=ark:/usr/local/home/nesrez/kaldi/egs/librispeech/s5/fmllr/train_clean_100/utt2spk  ark:/usr/local/home/nesrez/kaldi/egs/librispeech/s5/fmllr/train_clean_100/data/cmvn_speaker.ark ark:- ark:- | add-deltas --delta-order=0 ark:- ark:- |
    cw_left=0
    cw_right=0

    
lab:lab_name=lab_cd
    lab_folder=/usr/local/home/nesrez/kaldi/egs/librispeech/s5/exp/tri4b/
    lab_opts=ali-to-pdf 
    lab_count_file=auto
    lab_data_folder=/usr/local/home/nesrez/kaldi/egs/librispeech/s5/fmllr/train_clean_100/
    lab_graph=/usr/local/home/nesrez/kaldi/egs/librispeech/s5/exp/tri4b/graph_tgsmall/

N_chunks=10
        
[dataset2]
data_name=dev_clean
fea:fea_name=fmllr
    fea_lst=/usr/local/home/nesrez/kaldi/egs/librispeech/s5/fmllr/dev_clean/feats.scp
    fea_opts=apply-cmvn --utt2spk=ark:/usr/local/home/nesrez/kaldi/egs/librispeech/s5/fmllr/dev_clean/utt2spk  ark:/usr/local/home/nesrez/kaldi/egs/librispeech/s5/fmllr/dev_clean/data/cmvn_speaker.ark ark:- ark:- | add-deltas --delta-order=0 ark:- ark:- |
    cw_left=0
    cw_right=0


lab:lab_name=lab_cd
    lab_folder=/usr/local/home/nesrez/kaldi/egs/librispeech/s5/exp/tri4b_ali_dev_clean_100
    lab_opts=ali-to-pdf 
    lab_count_file=auto
    lab_data_folder=/usr/local/home/nesrez/kaldi/egs/librispeech/s5/fmllr/dev_clean/
    lab_graph=/usr/local/home/nesrez/kaldi/egs/librispeech/s5/exp/tri4b/graph_tgsmall/

N_chunks=10

[dataset3]
data_name=test_clean
fea:fea_name=fmllr
    fea_lst=/usr/local/home/nesrez/kaldi/egs/librispeech/s5/fmllr/test_clean/feats.scp
    fea_opts=apply-cmvn --utt2spk=ark:/usr/local/home/nesrez/kaldi/egs/librispeech/s5/fmllr/test_clean/utt2spk  ark:/usr/local/home/nesrez/kaldi/egs/librispeech/s5/fmllr/test_clean/data/cmvn_speaker.ark ark:- ark:- | add-deltas --delta-order=0 ark:- ark:- |
    cw_left=0
    cw_right=0


lab:lab_name=lab_cd
    lab_folder=/usr/local/home/nesrez/kaldi/egs/librispeech/s5/exp/tri4b_ali_test_clean_100
    lab_opts=ali-to-pdf 
    lab_count_file=auto
    lab_data_folder=/usr/local/home/nesrez/kaldi/egs/librispeech/s5/fmllr/test_clean/
    lab_graph=/usr/local/home/nesrez/kaldi/egs/librispeech/s5/exp/tri4b/graph_tgsmall/

N_chunks=8

        
[data_use]
train_with=train_clean_100
valid_with=dev_clean
forward_with=test_clean


[batches]
batch_size_train=16
max_seq_length_train=500
increase_seq_length_train=True
start_seq_len_train=100
multply_factor_seq_len_train=2
batch_size_valid=8
max_seq_length_valid=1000

[architecture1]
arch_name = LSTM_layers
arch_proto = proto/LSTM.proto
arch_library = neural_networks
arch_class = LSTM
arch_pretrain_file = none
arch_freeze = False
arch_seq_model = True
lstm_lay = 550,550,550,550
lstm_drop = 0.2,0.2,0.2,0.2
lstm_use_laynorm_inp = False
lstm_use_batchnorm_inp = False
lstm_use_laynorm = False,False,False,False
lstm_use_batchnorm = True,True,True,True
lstm_bidir = True
lstm_act = tanh,tanh,tanh,tanh
lstm_orthinit=True

arch_lr = 0.0016
arch_halving_factor = 0.5
arch_improvement_threshold = 0.001
arch_opt = rmsprop
opt_momentum = 0.0
opt_alpha = 0.95
opt_eps = 1e-8
opt_centered = False
opt_weight_decay = 0.0
quantize = False
number_of_bits = 4
weights_bits = 16,16,16,16
weights_activation_bits = 16,16,16,16
activations_x_avg = 9,10.2,7.5,6.5,10.7,10.7,11.5,11.6
activations_x_max = 11.4,12.9,9.4,8.1,16,15.8,16.5,16.4
activations_h_avg = 0.04,0.05,0.04,0.04,0.77,0.07,0.08,0.09,0.07,1
activations_h_max = 1000.3,1001.8,1000.5,1000.7,1,1001,1001,1004.7,1001.7,1
use_statistics = False
statistics = 1.9941757726669311,0.7235926085710526,0.3873774981498719,0.5697686612606048,0.799998688697815
default = 6.067001819610596,6.520757675170898,6.2589006423950195,9.417000770568848,9.261473655700684,10.611333847045898,12.594860076904297,11.850000381469727,0,0,0,0,0,0,0,0
conf_file = /usr/local/home/nesrez/pytorch-kaldi/exp/TIMIT_LSTM_fbank_c2/quantize_TIMIT.cfg
output_bits = 8
projection_bits = 16,16,16,16
delta_x = 0.11334192276759048,0.7548614813904674
delta_h = 0.027783348848669953,0.3948504804606394
delta_fc = 0.7469384956075252
sparsity_x = 47.82608413696289,71.4319839477539
sparsity_h = 39.6363639831543,51.3636360168457
default_x = 4.822748184204102,5.325120449066162,4.684037685394287,4.847898721694946,8.318682670593262,8.032586574554443,7.554445505142212,9.582362174987793
default_h = 4.872948169708252,4.954357147216797,4.696542739868164,3.9492297172546387,7.353921413421631,8.645167350769043,10.138763427734375,7.409567832946777
x_weights_bits = 2,8
x_weights_activation_bits = 4,2
h_weights_bits = 2,4
h_weights_activation_bits = 8,2

[architecture2]
arch_name=MLP_layers
arch_proto=proto/MLP.proto
arch_library=neural_networks
arch_class=MLP
arch_pretrain_file=none
arch_freeze=False
arch_seq_model=False
dnn_lay=N_out_lab_cd
dnn_drop=0.0
dnn_use_laynorm_inp=False
dnn_use_batchnorm_inp=False
dnn_use_batchnorm=False
dnn_use_laynorm=False
dnn_act=softmax

arch_lr=0.0004
arch_halving_factor=0.5
arch_improvement_threshold=0.001
arch_opt=rmsprop
opt_momentum=0.0
opt_alpha=0.95
opt_eps=1e-8
opt_centered=False
opt_weight_decay=0.0
quantize = False
number_of_bits = 8
minimum = -128
maximum = 127
skip_layer_0 = False
expand_ratio = 1
ocs_file = exp/TIMIT_LSTM_fbank_N8/OCS1.txt
activations_x_avg = 9
activations_x_max = 11.4
activations_h_avg = 0.04
activations_h_max = 1000.3
stat = False
conf_file = /usr/local/home/nesrez/pytorch-kaldi/exp/TIMIT_LSTM_fbank_c2/quantize_TIMIT.cfg
delta = 0.7469384956075252
sparsity = 73.37353515625
default = 0


[model]
model_proto=proto/model.proto
model:out_dnn1=compute(LSTM_layers,fmllr)
      out_dnn2=compute(MLP_layers,out_dnn1)
      loss_final=cost_nll(out_dnn2,lab_cd)
      err_final=cost_err(out_dnn2,lab_cd)


[forward]
forward_out=out_dnn2
normalize_posteriors=True
normalize_with_counts_from=lab_cd
save_out_file=False
require_decoding=True


[decoding]
decoding_script_folder=kaldi_decoding_scripts/
decoding_script=decode_dnn.sh
decoding_proto=proto/decoding.proto
min_active=200
max_active=7000
max_mem=50000000
beam=20.0
latbeam=12.0
acwt=0.10
max_arcs=-1
skip_scoring=false
scoring_script=/usr/local/home/nesrez/kaldi/egs/librispeech/s5/local/score.sh
scoring_opts="--min-lmwt 4 --max-lmwt 23"
norm_vars=False

